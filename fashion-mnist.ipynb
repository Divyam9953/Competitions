{"cells":[{"metadata":{},"cell_type":"markdown","source":"Context\nFashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n\nThe original MNIST dataset contains a lot of handwritten digits. Members of the AI/ML/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset researchers try. \"If it doesn't work on MNIST, it won't work at all\", they said. \"Well, if it does work on MNIST, it may still fail on others.\"\n\nZalando seeks to replace the original MNIST dataset\n\nContent\n- Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n\n- To locate a pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix. For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.\n\n\nLabels --->\n\n0. T-shirt/top\n1. Trouser\n2. Pullover\n3. Dress\n4. Coat\n5. Sandal\n6. Shirt\n7. Sneaker\n8. Bag\n9. Ankle boot\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.utils import to_categorical","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/fashionmnist/fashion-mnist_train.csv')\ntest = pd.read_csv('../input/fashionmnist/fashion-mnist_test.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training Data:', train.shape)\nprint('Test Data:', test.shape)","execution_count":3,"outputs":[{"output_type":"stream","text":"Training Data: (60000, 785)\nTest Data: (10000, 785)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = np.array(train.drop('label',axis=1))\ntrain_Y = np.array(train['label'])\ntest_X = np.array(test.drop('label',axis=1))\ntest_Y = np.array(test['label'])","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X.shape,train_Y.shape,test_X.shape,test_Y.shape","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"((60000, 784), (60000,), (10000, 784), (10000,))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = np.unique(train_Y)\nnclasses = len(classes)\nprint('Total number of classes:', nclasses)\nprint('Output classes:', classes)","execution_count":6,"outputs":[{"output_type":"stream","text":"Total number of classes: 10\nOutput classes: [0 1 2 3 4 5 6 7 8 9]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Preprocessing\ntrain_X = train_X.reshape(-1,28,28,1)\ntest_X = test_X.reshape(-1,28,28,1)\ntrain_X.shape,test_X.shape","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"((60000, 28, 28, 1), (10000, 28, 28, 1))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing datatype\ntrain_X = train_X.astype('float32')\ntest_X = test_X.astype('float32')\n# Rescaling the pixel values\ntrain_X = train_X/255.0\ntest_X = test_X/255.0","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing the labels from categorical to one hot encoding\ntrain_Y_one_hot = to_categorical(train_Y)\ntest_Y_one_hot = to_categorical(test_Y)\n\n# Display the change for category label using one-hot encoding\nprint('Original label:', train_Y[0])\nprint('After conversion to one-hot:', train_Y_one_hot[0])","execution_count":9,"outputs":[{"output_type":"stream","text":"Original label: 2\nAfter conversion to one-hot: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the data\nfrom sklearn.model_selection import train_test_split\ntrain_X, valid_X, train_label, valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing libraries for Modelling the Data\nimport keras\nfrom keras.models import Sequential, Input, Model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nepochs = 20\nnum_classes = 10","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fashion_model = Sequential()\n\nfashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(28,28,1)))\nfashion_model.add(LeakyReLU(alpha=0.1))\nfashion_model.add(MaxPooling2D((2, 2),padding='same'))\nfashion_model.add(Dropout(0.25))\n\nfashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\nfashion_model.add(LeakyReLU(alpha=0.1))\nfashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nfashion_model.add(Dropout(0.25))\n\nfashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\nfashion_model.add(LeakyReLU(alpha=0.1))                  \nfashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nfashion_model.add(Dropout(0.4))\n\nfashion_model.add(Flatten())\nfashion_model.add(Dense(128, activation='linear'))\nfashion_model.add(LeakyReLU(alpha=0.1))           \nfashion_model.add(Dropout(0.3))\nfashion_model.add(Dense(num_classes, activation='softmax'))","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fashion_model.summary()","execution_count":14,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 28, 28, 32)        320       \n_________________________________________________________________\nleaky_re_lu (LeakyReLU)      (None, 28, 28, 32)        0         \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 14, 14, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 7, 7, 64)          0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n_________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 128)         0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 4, 4, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2048)              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               262272    \n_________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)    (None, 128)               0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 356,234\nTrainable params: 356,234\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fashion_train_dropout = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))","execution_count":16,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n750/750 [==============================] - 4s 5ms/step - loss: 0.6085 - accuracy: 0.7722 - val_loss: 0.3707 - val_accuracy: 0.8621\nEpoch 2/20\n750/750 [==============================] - 3s 5ms/step - loss: 0.3857 - accuracy: 0.8605 - val_loss: 0.3171 - val_accuracy: 0.8837\nEpoch 3/20\n750/750 [==============================] - 5s 6ms/step - loss: 0.3355 - accuracy: 0.8774 - val_loss: 0.2916 - val_accuracy: 0.8917\nEpoch 4/20\n750/750 [==============================] - 4s 5ms/step - loss: 0.3086 - accuracy: 0.8867 - val_loss: 0.2648 - val_accuracy: 0.9017\nEpoch 5/20\n750/750 [==============================] - 3s 5ms/step - loss: 0.2863 - accuracy: 0.8943 - val_loss: 0.2605 - val_accuracy: 0.9019\nEpoch 6/20\n750/750 [==============================] - 4s 5ms/step - loss: 0.2733 - accuracy: 0.8989 - val_loss: 0.2515 - val_accuracy: 0.9066\nEpoch 7/20\n750/750 [==============================] - 3s 4ms/step - loss: 0.2603 - accuracy: 0.9037 - val_loss: 0.2377 - val_accuracy: 0.9115\nEpoch 8/20\n750/750 [==============================] - 3s 5ms/step - loss: 0.2521 - accuracy: 0.9061 - val_loss: 0.2334 - val_accuracy: 0.9112\nEpoch 9/20\n750/750 [==============================] - 4s 5ms/step - loss: 0.2412 - accuracy: 0.9108 - val_loss: 0.2319 - val_accuracy: 0.9133\nEpoch 10/20\n750/750 [==============================] - 4s 5ms/step - loss: 0.2381 - accuracy: 0.9112 - val_loss: 0.2154 - val_accuracy: 0.9186\nEpoch 11/20\n750/750 [==============================] - 4s 5ms/step - loss: 0.2327 - accuracy: 0.9114 - val_loss: 0.2311 - val_accuracy: 0.9170\nEpoch 12/20\n750/750 [==============================] - 4s 5ms/step - loss: 0.2237 - accuracy: 0.9153 - val_loss: 0.2128 - val_accuracy: 0.9224\nEpoch 13/20\n750/750 [==============================] - 3s 5ms/step - loss: 0.2223 - accuracy: 0.9171 - val_loss: 0.2185 - val_accuracy: 0.9196\nEpoch 14/20\n750/750 [==============================] - 3s 4ms/step - loss: 0.2193 - accuracy: 0.9185 - val_loss: 0.2152 - val_accuracy: 0.9212\nEpoch 15/20\n750/750 [==============================] - 4s 5ms/step - loss: 0.2156 - accuracy: 0.9199 - val_loss: 0.2084 - val_accuracy: 0.9239\nEpoch 16/20\n750/750 [==============================] - 3s 5ms/step - loss: 0.2125 - accuracy: 0.9208 - val_loss: 0.2097 - val_accuracy: 0.9237\nEpoch 17/20\n750/750 [==============================] - 3s 5ms/step - loss: 0.2066 - accuracy: 0.9222 - val_loss: 0.2054 - val_accuracy: 0.9251\nEpoch 18/20\n750/750 [==============================] - 4s 5ms/step - loss: 0.2046 - accuracy: 0.9238 - val_loss: 0.2088 - val_accuracy: 0.9252\nEpoch 19/20\n750/750 [==============================] - 3s 5ms/step - loss: 0.2033 - accuracy: 0.9244 - val_loss: 0.2077 - val_accuracy: 0.9276\nEpoch 20/20\n750/750 [==============================] - 4s 5ms/step - loss: 0.2000 - accuracy: 0.9252 - val_loss: 0.2062 - val_accuracy: 0.9259\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Evaluation on Test Data\ntest_eval = fashion_model.evaluate(test_X, test_Y_one_hot, verbose=1)","execution_count":17,"outputs":[{"output_type":"stream","text":"313/313 [==============================] - 1s 3ms/step - loss: 0.2052 - accuracy: 0.9292\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}